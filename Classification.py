# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TBPoe1JWGzNg3c5wxmKmQP-Po5ZWCz0Z

# Import Libraries:-
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler,MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

df = pd.read_csv("train_data.csv")
df.head()

"""# Drop "case_id" column:-"""

df = df.drop(["case_id"], axis = 1)

"""# Drop rows having missing values:-"""

df.isnull().sum()

"""# Finding correlation between feature using pearson method:-"""

corr = df.corr(method='pearson')
# cmap = sns.diverging_palette(250, 354,80,60,center='dark',as_cmap=True)
# sns.heatmap(corr, cmap=plt.cm.CMRmap_r, annot=True)
sns.heatmap(corr, cmap=plt.cm.CMRmap_r, annot=True)

df = df.dropna(axis = 0)

df.isnull().sum()

"""# LabelEncoding of the feature:-"""

cols = ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age' ]
df[cols] = df[cols].apply(LabelEncoder().fit_transform)
df.head()

X = df.iloc[:, :-1]
y = df.iloc[:, -1]
X.head()
y.head()

y.hist(figsize=(18,7), bins = 20)

"""# Split data into train test:-"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

X_train.head()

"""# Standardization of values:-"""

# sc = StandardScaler()
sc = MinMaxScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print(X_train)
print(X_test)

"""# Decision Tree Classifier:-"""

classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print("\n Decision Tree Accuracy: ", accuracy_score(y_test, y_pred))

import matplotlib.pyplot as plt
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""# Random Forest Classifier:-"""

classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print("\nRandom Forest Accuracy: ", accuracy_score(y_test, y_pred))

"""# Naive Bayes Classifier:-"""

classifier = GaussianNB()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print("\nNaive Bayes Accuracy: ", accuracy_score(y_test, y_pred))

"""# KNN Classifier:-"""

classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 1)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print("\nKNN Accuracy: ", accuracy_score(y_test, y_pred))

"""# Logistic Regression:-"""

from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0).fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("\nLogistic Regression Accuracy: ", accuracy_score(y_test, y_pred))

"""# Stratified KFold cross validation:-"""

def get_score(model, X_train, X_test, y_train, y_test):
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  return accuracy_score(y_pred, y_test)

folds = StratifiedKFold(n_splits=5)

accuracy_dec_tree = []
accuracy_random_forest = []
accuracy_kclassifier = []
accuracy_naivebayes = []
accuracy_logistic_regression = []

#Different k-fold cross validation with different classifier
for train_i, test_i in folds.split(X, y):
  X_train, X_test, y_train, y_test = X.iloc[list(train_i)], X.iloc[list(test_i)],y.iloc[list(train_i)], y.iloc[list(test_i)]
  scal = StandardScaler()
  X_train = scal.fit_transform(X_train)
  X_test = scal.transform(X_test)
  accuracy_dec_tree.append( get_score(DecisionTreeClassifier(criterion = 'entropy', random_state = 0),X_train, X_test, y_train, y_test) )
  accuracy_random_forest.append( get_score(RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0),X_train, X_test, y_train, y_test) )
  accuracy_naivebayes.append( get_score(GaussianNB(),X_train, X_test, y_train, y_test) )
  accuracy_kclassifier.append( get_score(KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2),X_train, X_test, y_train, y_test) )
  accuracy_logistic_regression.append( get_score(LogisticRegression(random_state=0),X_train, X_test, y_train, y_test) )

#Printing accuracy for all approaches with cross validation
print("\nDecision Tree Accuracy for 5 different fold: ", accuracy_dec_tree)
print("\nDecision Tree Accuracy: ", np.mean(accuracy_dec_tree))

print("\nRandom Forest for 5 different fold: ",accuracy_random_forest)
print("\nRandom Forest: ",np.mean(accuracy_random_forest))

print("\nKNN for 5 different fold: ",accuracy_kclassifier)
print("\nKNN: ",np.mean(accuracy_kclassifier))

print("\nNaive Bayes for 5 different fold: ",accuracy_naivebayes)
print("\nNaive Bayes: ",np.mean(accuracy_naivebayes))

print("\nLogistic Regression for 5 different fold: ",accuracy_logistic_regression)
print("\nLogistic Regression: ",np.mean(accuracy_logistic_regression))